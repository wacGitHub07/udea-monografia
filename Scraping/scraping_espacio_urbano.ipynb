{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para ejecutar el proceso de extracción de datos del sítio https://www.espaciourbano.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de archivos en utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de listado de users agents\n",
    "user_agets = pd.read_csv(\"utils/user-agent.csv\")\n",
    "\n",
    "# Carga de listado de proxies\n",
    "with open(\"utils/proxies.json\") as json_file:\n",
    "    proxies = json.load(json_file)\n",
    "proxies = proxies.get(\"proxies\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiciones de URLs**\n",
    "\n",
    "El sitio espacio urbano contiene 5 zonas para casas en alquiler en la ciudad de Medellín:\n",
    "- Centro\n",
    "- Poblado\n",
    "- Belen\n",
    "- Laureles\n",
    "- San Antonio de Prado\n",
    "\n",
    "Cada una de las zonas contiene una URL producto de interactuar con el sitio y hacer los respectivos filtros por zonas, además cada una de estas puede tener resultados en n páginas, estas urls se definen a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Principal\n",
    "head_url = \"https://www.espaciourbano.com/\"\n",
    "\n",
    "# URL Zona Centro\n",
    "urls_zona_centro   = [\"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10000&pTipoInmueble=1&nCiudad=Medellin%20Zona%201%20-%20Centro\",          # Página 1\n",
    "                      \"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10000&pTipoInmueble=1&nCiudad=Medellin+Zona+1+%2D+Centro&offset={limit}\"] # Página n\n",
    "\n",
    "# URL Zona Poblado\n",
    "urls_poblado = [\"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10027&pTipoInmueble=1&nCiudad=Medellin%20Zona%202%20-%20El%20Poblado\",         # Página 1\n",
    "                \"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10027&pTipoInmueble=1&nCiudad=Medellin+Zona+2+%2D+El+Poblado&offset={limit}\"]  # Página n\n",
    "\n",
    "# URL Zona Belen\n",
    "urls_belen = [\"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10029&pTipoInmueble=1&nCiudad=Medellin%20Zona%204%20-%20Belen\",          # Página 1\n",
    "              \"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10029&pTipoInmueble=1&nCiudad=Medellin+Zona+4+%2D+Belen&offset={limit}\"] # Página n\n",
    "\n",
    "# URL Laureles\n",
    "urls_laureles = [\"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10028&pTipoInmueble=1&nCiudad=Medellin%20Zona%203%20-%20Laureles\",          # Página 1\n",
    "                 \"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10028&pTipoInmueble=1&nCiudad=Medellin+Zona+3+%2D+Laureles&offset={limit}\"] # Página n\n",
    "\n",
    "# URL San Antonio de Prado\n",
    "urls_san_antonio = [\"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10041&pTipoInmueble=1&nCiudad=San%20Antonio%20de%20Prado\",          # Página 1\n",
    "                    \"https://www.espaciourbano.com/resumen_ciudad_arriendos.asp?pCiudad=10041&pTipoInmueble=1&nCiudad=San+Antonio+de+Prado&offset={limit}\"] # Página n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones:**\n",
    "\n",
    "La información de cada uno de los inmuebles esta dividida en\n",
    "- Precio\n",
    "- Zona\n",
    "- Comonidades\n",
    "- Caracteristicas\n",
    "\n",
    "Se define una función que realiza la petición a cada sitio y extrae la información de cada inmueble con el respectivo código de registro de la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties_info(url: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Función para realizar la petición a una url especifica\n",
    "    y devolver los datos de cada inmueble\n",
    "\n",
    "    PARAMS\n",
    "        url: str\n",
    "            url de una página con el listado de los inmuenles en arriendo\n",
    "    RETURN\n",
    "        (cod, lease) tuple\n",
    "            código de un inmueble con su respectivo grupos de valores\n",
    "            precio, zona, comodidades y caracteristicas\n",
    "    \"\"\"\n",
    "    # Variar el user agent por petición\n",
    "    headers = {'User-Agent': user_agets.sample(1)[\"user-agent\"].values[0]}\n",
    "\n",
    "    # Consulta y carga de la url de detalle\n",
    "    detail = requests.get(url.replace(\"Ficha\",\"ficha\"), headers=headers)\n",
    "\n",
    "    soup_detail =BeautifulSoup(detail.content,'lxml')\n",
    "\n",
    "    # Obtención del código de vivienda, precio y zona\n",
    "    price_zone = soup_detail.find_all('div', attrs={'class':'text-center'})\n",
    "    price_zone = price_zone[1].find_all('h3')\n",
    "    code = soup_detail.find_all('div', attrs={'class':'text-center'})[0].text.strip()\n",
    "    price = price_zone[0].text.replace(\"\\r\\n\",\"\").strip()\n",
    "    zone = price_zone[2].text\n",
    "\n",
    "    # Obtención de las comodidades\n",
    "    comforts = []\n",
    "    comforts_div = soup_detail.find('div', attrs={'class' : 'col-lg-4'}).find_all('p')\n",
    "    for com in comforts_div:\n",
    "        comfort = com.text.strip()\n",
    "        if comfort != \"\": \n",
    "            comforts.append(comfort)\n",
    "\n",
    "    \n",
    "    # Obtención de las características\n",
    "    characteristics = {}\n",
    "    characteristics_div = soup_detail.find('div', attrs={'class' : 'col-lg-8'}).find('table').find_all('tr')\n",
    "    for cha in characteristics_div:\n",
    "        row_cha = cha.find_all('td')\n",
    "        characteristics[row_cha[0].text.strip()] = row_cha[1].text.strip()\n",
    "\n",
    "    lease = {\n",
    "        \"precio\" : price,\n",
    "        \"zona\" : zone,\n",
    "        \"comodidades\" : comforts,\n",
    "        \"caracteristicas\" : characteristics\n",
    "    }\n",
    "\n",
    "    # retorno de valores\n",
    "    return code, lease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone_info(urls: list,\n",
    "                  pages: int,\n",
    "                  path: int,\n",
    "                  zona: str = \"\") -> tuple:\n",
    "    \"\"\"\n",
    "    Función para consultar la información de los inmuebles por cada zona\n",
    "    PARAMS\n",
    "        urls:lis\n",
    "            Lista de las urls por zona\n",
    "        pages: int\n",
    "            Cantidad de páginas que tiene cada zona\n",
    "        path: int\n",
    "            Salto de página de cada sitio\n",
    "        zona: str\n",
    "            Nombre de zona que se esta procesando\n",
    "    RETURN\n",
    "        leases: dict\n",
    "            Información de los inmuebles por zona\n",
    "        characteristics: set\n",
    "            Consolidado de los tipos de características por zona\n",
    "        comforts: set\n",
    "            Consolidado de las diferentes comodidades por zona\n",
    "    \"\"\"\n",
    "\n",
    "    # Diccionario para almacenar los resultados\n",
    "    leases = {}\n",
    "    # Conjuntos para almacenar los consolidados de\n",
    "    # Comodidades y características\n",
    "    characteristics = set()\n",
    "    comforts = set()\n",
    "\n",
    "    print(f\"Consultando Zona: {zona}\")\n",
    "\n",
    "    for i in range(0, pages):\n",
    "        \n",
    "        user_agets.sample(1)[\"user-agent\"].values[0]\n",
    "        # Se selecciona un agente de forma aleatoria\n",
    "        headers = {'User-Agent': user_agets.sample(1)[\"user-agent\"].values[0]}\n",
    "        \n",
    "        # Selección de la página a consultar\n",
    "        if i == 0:\n",
    "            url = urls[0]\n",
    "        else:\n",
    "            url = urls[1].format(pages = i*path)\n",
    "\n",
    "        print(f\"-- Consultando página : {i*path}\")\n",
    "        response = requests.get(url,headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Por medio de BeautifulSoup se extrae el contendio de la pagina \n",
    "            soup_list = BeautifulSoup(response.content,'lxml')\n",
    "\n",
    "            # Cargar todas las clases div con para obtener el detalle de las viviendas\n",
    "            urls_details = soup_list.find_all('div', attrs={'class' : 'col-sm-4'})\n",
    "            urls_details.pop(0)\n",
    "            for url_detail in urls_details:\n",
    "                a = url_detail.find('a')\n",
    "                url = head_url + a.get('href')\n",
    "                code, lease = get_properties_info(url)\n",
    "                leases[code] = lease\n",
    "                characteristics = characteristics.union(set(lease[\"caracteristicas\"].keys()))\n",
    "                comforts = comforts.union(set(lease[\"comodidades\"]))\n",
    "        else:\n",
    "            print(\"ERROR: Falla consultando url: {}\".format(url))\n",
    "    return leases, characteristics, comforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data: set, file_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Función para imprimir datos en un archivo .txt\n",
    "    PARAMS\n",
    "        data: set\n",
    "            Conjunto con los datos a imprimir en el archivo\n",
    "        file_name: str\n",
    "            Nombre del archivo a crear\n",
    "    RETUN\n",
    "    \n",
    "    \"\"\"\n",
    "    # Transfomación de los datos a una lista\n",
    "    data = list(data)\n",
    "    # Crear archivo sobre el cual se va a escribir\n",
    "    with open(f'{file_name}.txt', 'w') as f:\n",
    "        # Ciclo para escribir cada línea en el archivo\n",
    "        for line in data:\n",
    "            f.write(line + '\\n')\n",
    "    f.close"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ejecución de proceso de peticiones o requests:***\n",
    "\n",
    "Teniendo las urls y las funciones se procede a ejecutar el proceso de extracción de información por cada zona, en este proceso se deben generar 3 archivos:\n",
    "- .json: archivo json por zona con la informacion de los inmuebles\n",
    "- .txt: archivo con el consolidado de las características de todos los inmuebles de cada zona\n",
    "- .txt: archivo con el consolidado de las comodidades de todos los inmuebles de cada zona\n",
    "\n",
    "Los archivos de comodidades y características se deben generar para crear una variable booleana con cada uno de los valores de estos archivos, por tanto por cada inmueble se tendrá una variable booleana que indique si tiene o no dicha caracteristica\n",
    "\n",
    "Estos resultados serán almacenados en la carpeta _resultados_request_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping: Zona San Antonio de Prado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "urls = urls_san_antonio\n",
    "pages = 2 # Número de páginas del sitio\n",
    "path = 50 # Indica el salto de página\n",
    "file_name = \"resultados_request/zona_5_san_antonio\"\n",
    "characteristics_file = \"resultados_request/zona_5_san_antonio_carac\"\n",
    "comforts_file = \"resultados_request/zona_5_san_antonio_com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución del scraping\n",
    "leases, characteristics, comforts = get_zone_info(urls,\n",
    "                                                  pages,\n",
    "                                                  path,\n",
    "                                                  zona = \"San Antonio de Prado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{file_name}.json\", \"w\", encoding='utf-8') as outfile:\n",
    "    json.dump(leases, outfile)\n",
    "\n",
    "write_file(characteristics, characteristics_file)\n",
    "write_file(comforts_file, comforts_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
